{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db69bb9",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da749df",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare the means of three or more groups to determine if there are significant differences among them. To use ANOVA effectively, several assumptions must be met. Violations of these assumptions can impact the validity of the results. The key assumptions for ANOVA are:\n",
    "\n",
    "1. **Independence**: Observations within each group are assumed to be independent of each other. Violations can occur when observations are not independent. For example, if you're comparing the test scores of students in different schools, and some schools have shared curriculum or teachers, the independence assumption may be violated.\n",
    "\n",
    "2. **Normality**: The residuals (the differences between individual data points and the group means) should be normally distributed for each group. Violations can occur when the data within groups are not approximately normally distributed. This can be assessed using statistical tests like the Shapiro-Wilk test or by inspecting Q-Q plots. For example, if you're comparing the response times of two different groups and one group's response times are heavily skewed, this could violate the normality assumption.\n",
    "\n",
    "3. **Homogeneity of Variance (Homoscedasticity)**: The variance of the residuals should be approximately equal across all groups. Violations can occur when the variances are not equal. You can use statistical tests like Levene's test or Bartlett's test to check for homoscedasticity. For example, if you're comparing the yields of three different types of crops, and one crop shows much larger variation than the others, this could violate the homogeneity of variance assumption.\n",
    "\n",
    "4. **Random Sampling**: The samples should be drawn randomly from the population. Violations can occur when the samples are not truly random, leading to selection bias.\n",
    "\n",
    "5. **Equality of Group Sizes**: It is assumed that the groups have roughly equal sample sizes. If group sizes are highly imbalanced, it can affect the power of the ANOVA and lead to unequal representation.\n",
    "\n",
    "6. **Continuous Dependent Variable**: ANOVA assumes that the dependent variable is measured on a continuous scale. Categorical or ordinal data may not be appropriate for ANOVA, and you may need to consider non-parametric tests.\n",
    "\n",
    "Violations of these assumptions can impact the validity of ANOVA results by potentially leading to false positive or false negative conclusions. If assumptions are not met, it may be necessary to use alternative statistical tests or transformations of the data to address the issues. Additionally, robust ANOVA techniques or non-parametric tests can be used when some assumptions are violated. It's important to perform exploratory data analysis and diagnostics to assess the extent of these violations and decide on the most appropriate analysis method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a86dd",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55219c",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical technique used to compare means among multiple groups. There are three main types of ANOVA, each used in specific situations:\n",
    "\n",
    "1. **One-Way ANOVA**:\n",
    "   - **Use**: One-Way ANOVA is used when you have one categorical independent variable (with more than two levels or groups) and one continuous dependent variable.\n",
    "   - **Example**: You want to compare the mean test scores of students from three different schools to determine if there is a significant difference in performance. School (School A, School B, School C) is the categorical independent variable, and the test scores are the continuous dependent variable.\n",
    "\n",
    "2. **Two-Way ANOVA**:\n",
    "   - **Use**: Two-Way ANOVA is used when you have two categorical independent variables (factors) and one continuous dependent variable. It is used to assess the interaction between the two factors and their individual effects.\n",
    "   - **Example**: You want to determine if both the type of diet (Factor A: Diet 1, Diet 2, Diet 3) and the gender of the participants (Factor B: Male, Female) have an effect on weight loss (the continuous dependent variable). Two-Way ANOVA allows you to assess the main effects of diet and gender and their interaction.\n",
    "\n",
    "3. **Repeated Measures ANOVA**:\n",
    "   - **Use**: Repeated Measures ANOVA is used when you have a within-subjects design, where each subject is measured under multiple conditions or time points. It's used to assess the impact of a single categorical independent variable (factor) when the same subjects are measured repeatedly.\n",
    "   - **Example**: You want to measure the effect of a drug (Factor: Drug A, Drug B) on blood pressure in the same group of patients at baseline and after 1 hour, 2 hours, and 4 hours. Repeated Measures ANOVA helps assess whether there are significant differences in blood pressure due to the type of drug and the interaction between drug type and time.\n",
    "\n",
    "In summary:\n",
    "\n",
    "- One-Way ANOVA is used for one categorical independent variable with multiple levels.\n",
    "- Two-Way ANOVA is used for two categorical independent variables, assessing main effects and interactions.\n",
    "- Repeated Measures ANOVA is used for within-subject designs with repeated measurements on the same subjects under different conditions or time points.\n",
    "\n",
    "The choice of ANOVA type depends on the experimental design and the research questions you want to address. It's important to understand the nature of your data and how it fits with each type of ANOVA to make the appropriate selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910396fa",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd077d5",
   "metadata": {},
   "source": [
    "The partitioning of variance is a fundamental concept in analysis of variance (ANOVA). It refers to the division of the total variance in a dataset into different components or sources of variation. Understanding this concept is essential for several reasons:\n",
    "\n",
    "1. **Identifying Sources of Variation**: ANOVA helps us decompose the total variation observed in a dataset into different sources. It helps us understand where the variability in the data comes from. These sources of variation are categorized into three main components in a one-way ANOVA:\n",
    "\n",
    "   - **Between-Group Variation (SSB)**: This represents the differences between the group means. It measures the effect of the independent variable (or factor) on the dependent variable. If SSB is large relative to the within-group variation, it suggests that the independent variable has a significant effect on the dependent variable.\n",
    "\n",
    "   - **Within-Group Variation (SSW)**: This represents the variation within each group or category. It is often considered as random or error variance. High SSW indicates that there is considerable variability within each group, making it difficult to detect significant differences between groups.\n",
    "\n",
    "   - **Total Variation (SST)**: This is the overall variability in the dataset, and it's the sum of SSB and SSW. SST measures the total variance in the data without taking groupings into account.\n",
    "\n",
    "2. **Hypothesis Testing**: Understanding the partitioning of variance is crucial for hypothesis testing in ANOVA. By comparing the ratio of between-group variation to within-group variation, ANOVA tests whether the differences between groups are statistically significant. This forms the basis for concluding whether the independent variable has a significant effect.\n",
    "\n",
    "3. **Effect Size**: Partitioning of variance helps researchers assess the practical significance or effect size of the independent variable. A large proportion of between-group variation (compared to within-group variation) indicates a strong effect of the independent variable on the dependent variable.\n",
    "\n",
    "4. **Model Assessment**: Understanding the sources of variance allows researchers to assess the goodness of fit of the ANOVA model. If most of the variance is explained by the model, it suggests that the model is a good fit for the data.\n",
    "\n",
    "5. **Interpretation and Insights**: By examining the partitioned variance, researchers gain insights into the relative importance of different factors or groupings and can make informed interpretations about the study results.\n",
    "\n",
    "In summary, understanding the partitioning of variance in ANOVA is crucial for identifying the sources of variation in the data, performing hypothesis tests, assessing effect sizes, and drawing meaningful conclusions about the relationships between variables. It provides a structured and systematic approach for analyzing data and making inferences about the factors that influence the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8850a9f",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ae502",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, you can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) using Python. These are fundamental components of ANOVA that help you understand the variation in your data. Here's how you can calculate them:\n",
    "\n",
    "1.Total Sum of Squares (SST):\n",
    "SST measures the total variability in the data, which is the sum of squared differences between each data point and the overall mean.\n",
    "\n",
    "Formula: SST = Σ(yi - ȳ)², where yi is each individual data point, and ȳ is the overall mean.\n",
    "\n",
    "In Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6243fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [12, 15, 18, 20, 22, 28, 24, 26, 30, 32]  # Your data\n",
    "overall_mean = np.mean(data)\n",
    "SST = np.sum((data - overall_mean) ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041c59a",
   "metadata": {},
   "source": [
    "2.Explained Sum of Squares (SSE):\n",
    "SSE represents the variation that can be attributed to the differences between group means. It is the sum of squared differences between each group mean and the overall mean, weighted by the number of data points in each group.\n",
    "\n",
    "Formula: SSE = Σ(ni * (ȳi - ȳ)²), where ni is the number of data points in each group, ȳi is the mean of each group, and ȳ is the overall mean.\n",
    "\n",
    "In Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93af913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = [[12, 15, 18], [20, 22, 28], [24, 26, 30, 32]]  # Your grouped data\n",
    "group_means = [np.mean(group) for group in group_data]\n",
    "SSE = np.sum([len(group) * (group_mean - overall_mean) ** 2 for group, group_mean in zip(group_data, group_means)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478bb9e6",
   "metadata": {},
   "source": [
    "3.Residual Sum of Squares (SSR):\n",
    "SSR measures the unexplained variation or error in the data, which is the sum of squared differences between each data point and its group mean.\n",
    "\n",
    "Formula: SSR = Σ(yij - ȳi)², where yij is each individual data point in each group, and ȳi is the mean of each group.\n",
    "\n",
    "In Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ccf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSR = np.sum([(y - group_mean) ** 2 for group, group_mean in zip(group_data, group_means) for y in group])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e4d3cd",
   "metadata": {},
   "source": [
    "These calculations provide insights into how the variation in your data is partitioned into total variation, explained variation (due to group means), and unexplained variation (residuals). It's an essential part of the ANOVA analysis to determine if group means are significantly different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080ccb1",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccbc7b5",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, you can calculate the main effects and interaction effects using Python by analyzing the variation attributable to each factor and their interactions. Here's how you can calculate these effects:\n",
    "\n",
    "1.Main Effects:\n",
    "Main effects represent the impact of each individual independent variable (factor) on the dependent variable while ignoring the other factor(s). You can calculate the main effects by comparing the means of the dependent variable for each level of a factor.\n",
    "\n",
    "In Python, you can use libraries like NumPy or SciPy to calculate main effects. Let's assume you have a dataset where you're comparing the effect of two factors, Factor A and Factor B, on a dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b824f42a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "at least two inputs are required; got 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m factor_B \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate the main effect of Factor A\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m effect_A, p_A \u001b[38;5;241m=\u001b[39m \u001b[43mf_oneway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Calculate the main effect of Factor B\u001b[39;00m\n\u001b[0;32m     11\u001b[0m effect_B, p_B \u001b[38;5;241m=\u001b[39m f_oneway(factor_B)\n",
      "File \u001b[1;32m~\\anaconda3\\ashoka\\lib\\site-packages\\scipy\\stats\\_stats_py.py:3843\u001b[0m, in \u001b[0;36mf_oneway\u001b[1;34m(axis, *samples)\u001b[0m\n\u001b[0;32m   3714\u001b[0m \u001b[38;5;124;03m\"\"\"Perform one-way ANOVA.\u001b[39;00m\n\u001b[0;32m   3715\u001b[0m \n\u001b[0;32m   3716\u001b[0m \u001b[38;5;124;03mThe one-way ANOVA tests the null hypothesis that two or more groups have\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3840\u001b[0m \n\u001b[0;32m   3841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(samples) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 3843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least two inputs are required;\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   3844\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(samples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3846\u001b[0m samples \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(sample, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[0;32m   3848\u001b[0m \u001b[38;5;66;03m# ANOVA on N groups, each in its own array\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: at least two inputs are required; got 1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Data for the two factors\n",
    "factor_A = [20, 25, 30, 35]\n",
    "factor_B = [15, 30, 20, 25]\n",
    "\n",
    "# Calculate the main effect of Factor A\n",
    "effect_A, p_A = f_oneway(factor_A)\n",
    "# Calculate the main effect of Factor B\n",
    "effect_B, p_B = f_oneway(factor_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac6d833",
   "metadata": {},
   "source": [
    "2.Interaction Effect:\n",
    "The interaction effect in a two-way ANOVA assesses whether the effect of one factor depends on the level of another factor. To calculate the interaction effect, you'll fit an ANOVA model that includes both factors and their interaction term (Factor A * Factor B). The interaction effect is represented by the interaction term's significance in the ANOVA model.\n",
    "\n",
    "In Python, you can use libraries like statsmodels or scipy to fit an ANOVA model and calculate the interaction effect. Assuming you have a dataset and want to assess the interaction effect between Factor A and Factor B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb84473a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ols\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with your data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFactor_A\u001b[39m\u001b[38;5;124m'\u001b[39m: factor_A, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFactor_B\u001b[39m\u001b[38;5;124m'\u001b[39m: factor_B, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDependent_Variable\u001b[39m\u001b[38;5;124m'\u001b[39m: dependent_variable})\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Fit a two-way ANOVA model with interaction\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m ols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDependent_Variable ~ Factor_A * Factor_B\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf)\u001b[38;5;241m.\u001b[39mfit()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with your data\n",
    "df = pd.DataFrame({'Factor_A': factor_A, 'Factor_B': factor_B, 'Dependent_Variable': dependent_variable})\n",
    "\n",
    "# Fit a two-way ANOVA model with interaction\n",
    "model = ols('Dependent_Variable ~ Factor_A * Factor_B', data=df).fit()\n",
    "\n",
    "# Get the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# The interaction effect p-value\n",
    "interaction_p_value = anova_table.loc['Factor_A:Factor_B', 'PR(>F)']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6843924",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28851ea",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, you use the F-statistic and its associated p-value to determine whether there are statistically significant differences between the groups. Here's how to interpret the results:\n",
    "\n",
    "1. **F-Statistic (F)**: The F-statistic quantifies the ratio of the variance between groups (explained variance) to the variance within groups (unexplained variance). It is calculated by comparing the means of the groups and assesses whether these means are significantly different from each other.\n",
    "\n",
    "2. **P-Value (p)**: The p-value associated with the F-statistic is used to determine the statistical significance of the differences between the groups. It tells you the probability of obtaining such results if there were no real differences between the groups.\n",
    "\n",
    "Given the F-statistic of 5.23 and a p-value of 0.02:\n",
    "\n",
    "- **Interpretation of the F-Statistic**: The F-statistic represents the variability in the data. A higher F-statistic suggests that the differences between group means are relatively large compared to the variability within the groups. In your case, an F-statistic of 5.23 indicates that there are differences in the group means.\n",
    "\n",
    "- **Interpretation of the P-Value**: The p-value (0.02) represents the probability of obtaining an F-statistic as extreme as the one observed in your data if there were no real differences between the groups. A small p-value (typically less than the chosen significance level, e.g., 0.05) suggests that the differences between the groups are statistically significant.\n",
    "\n",
    "- **Conclusion**: With a p-value of 0.02, which is less than the typical significance level of 0.05, you would conclude that there are statistically significant differences between at least some of the groups. In other words, the null hypothesis, which assumes that all group means are equal, can be rejected. \n",
    "\n",
    "- **Follow-up Analysis**: If you find statistically significant differences, it's common to conduct post-hoc tests (e.g., Tukey's HSD or Bonferroni) to identify which specific groups differ from each other.\n",
    "\n",
    "In summary, an F-statistic of 5.23 with a p-value of 0.02 indicates that there are statistically significant differences between the groups in your one-way ANOVA. This suggests that at least one group mean is different from the others, but you would need additional analysis to determine which specific group(s) differ from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f7afa",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1786a",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is a critical aspect of data analysis. Missing data can arise from various reasons, including participant dropout, technical issues, or incomplete responses. It's important to address missing data appropriately because it can impact the validity and reliability of your analysis. Here are some common methods for handling missing data and their potential consequences:\n",
    "\n",
    "1. **Listwise Deletion (Complete Case Analysis)**:\n",
    "   - **Method**: In listwise deletion, you remove cases (participants) with any missing data from the analysis. Only complete cases are included in the analysis.\n",
    "   - **Consequences**:\n",
    "     - Pros: Simple and retains the structure of the data.\n",
    "     - Cons: Reduces the sample size, potentially leading to reduced statistical power and less representative results. If missing data are not completely at random (MCAR), this method may introduce bias.\n",
    "\n",
    "2. **Pairwise Deletion**:\n",
    "   - **Method**: In pairwise deletion, you include all available data for each pair of variables. If a data point is missing for one variable, it is excluded only from the analyses involving that specific variable.\n",
    "   - **Consequences**:\n",
    "     - Pros: Maximizes the use of available data, preserving the sample size for each analysis.\n",
    "     - Cons: May introduce bias if missing data are not missing completely at random (MCAR) or may lead to different sample sizes for different analyses, which can complicate interpretation.\n",
    "\n",
    "3. **Imputation**:\n",
    "   - **Method**: Imputation involves estimating missing values and replacing them with reasonable substitutes. Common imputation methods include mean imputation, median imputation, regression imputation, or multiple imputations.\n",
    "   - **Consequences**:\n",
    "     - Pros: Retains the full sample size and minimizes bias in the presence of missing data. Multiple imputations provide estimates of variability.\n",
    "     - Cons: The imputed values are based on assumptions and may not accurately represent the true missing values. The choice of imputation method can affect results. Multiple imputations are computationally intensive.\n",
    "\n",
    "4. **Maximum Likelihood Estimation (MLE)**:\n",
    "   - **Method**: MLE is a statistical approach used in software packages capable of handling repeated measures ANOVA. It estimates parameters while accounting for missing data using likelihood-based methods.\n",
    "   - **Consequences**:\n",
    "     - Pros: Preserves the full sample size and is statistically efficient. It provides unbiased parameter estimates under the missing at random (MAR) assumption.\n",
    "     - Cons: May not be available in all statistical software packages.\n",
    "\n",
    "5. **Nonresponse and Sensitivity Analyses**:\n",
    "   - You can also perform sensitivity analyses to assess the impact of different missing data handling methods on your results. This helps understand the robustness of your findings.\n",
    "\n",
    "The choice of method for handling missing data depends on the nature of the data, the reasons for missingness, and the assumptions you are willing to make. It's important to document the method used and the rationale behind it in your research report. Additionally, sensitivity analyses can provide insights into the robustness of your results to different handling methods. Always aim for the method that maximizes the use of available data while minimizing bias, particularly when dealing with non-random missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa438b",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bdf252",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after an Analysis of Variance (ANOVA) to determine which specific groups or levels are significantly different from each other when the overall ANOVA results indicate significant differences. These tests help you make pairwise comparisons between groups. There are several common post-hoc tests, and the choice of which one to use depends on the design and assumptions of your study. Here are some common post-hoc tests and when you might use each one:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (Tukey's HSD)**:\n",
    "   - **Use**: Tukey's HSD is a widely used post-hoc test when you have equal group sizes and homogeneity of variances (homoscedasticity). It controls the familywise error rate, making it suitable for multiple comparisons.\n",
    "   - **Example**: In a one-way ANOVA comparing the effectiveness of four different treatments on pain relief, if the ANOVA result is significant, you would use Tukey's HSD to determine which specific treatments are significantly different from each other.\n",
    "\n",
    "2. **Bonferroni Correction**:\n",
    "   - **Use**: The Bonferroni correction is a conservative approach that is useful when you want to control the familywise error rate. It's appropriate for multiple comparisons, especially when you have unequal group sizes or heteroscedasticity.\n",
    "   - **Example**: In a study comparing the test scores of students from different schools, if you perform multiple pairwise comparisons, you may use the Bonferroni correction to adjust the significance level to maintain an acceptable Type I error rate.\n",
    "\n",
    "3. **Sidak Correction**:\n",
    "   - **Use**: The Sidak correction is another method to control the familywise error rate. It is less conservative than Bonferroni but still provides strong control over Type I errors.\n",
    "   - **Example**: If you are conducting multiple pairwise comparisons in a one-way ANOVA of product preferences among different age groups, you might use the Sidak correction to adjust the significance level for each comparison.\n",
    "\n",
    "4. **Dunnett's Test**:\n",
    "   - **Use**: Dunnett's test is designed for situations where you have a control group (or reference group) and want to compare all other groups to the control group. It is used for multiple comparisons with a control group.\n",
    "   - **Example**: In a clinical trial, you might have a control group and several treatment groups. Dunnett's test helps you determine if any of the treatment groups are significantly different from the control group.\n",
    "\n",
    "5. **Games-Howell**:\n",
    "   - **Use**: The Games-Howell test is suitable when you have unequal group sizes and heteroscedasticity (unequal variances). It is a non-parametric alternative to Tukey's HSD.\n",
    "   - **Example**: In a one-way ANOVA comparing the response times of different user groups on three different websites, you may use Games-Howell if group sizes and variances are not equal.\n",
    "\n",
    "6. **Holm-Bonferroni Procedure**:\n",
    "   - **Use**: The Holm-Bonferroni procedure is a step-down method that adjusts the significance level for multiple comparisons. It is used when you have multiple pairwise comparisons and want to control the familywise error rate.\n",
    "   - **Example**: In a study comparing the effects of various teaching methods on student performance in different subjects, you might use the Holm-Bonferroni procedure to adjust the significance level for all pairwise comparisons.\n",
    "\n",
    "The choice of post-hoc test depends on the specific design and assumptions of your study, as well as the level of control you want over the Type I error rate. It's essential to choose an appropriate post-hoc test to make valid and interpretable pairwise comparisons after obtaining a significant result in your ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e937d",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3809d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 89.54387836756474\n",
      "p-value: 2.9529123249469234e-20\n",
      "There is a significant difference between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for weight loss for each diet\n",
    "diet_A = [2.5, 3.1, 2.8, 2.4, 3.0, 3.2, 2.7, 2.9, 3.1, 2.6, 3.0, 2.8, 2.5, 2.9, 2.7, 2.6, 2.8, 3.0, 3.1, 2.5, 2.8, 2.7, 3.0, 2.6, 2.9]\n",
    "diet_B = [2.2, 2.3, 2.1, 2.4, 2.0, 2.5, 2.3, 2.2, 2.6, 2.1, 2.4, 2.5, 2.2, 2.3, 2.0, 2.6, 2.1, 2.4, 2.2, 2.3, 2.4, 2.6, 2.2, 2.5, 2.3]\n",
    "diet_C = [2.0, 1.9, 2.1, 2.2, 1.8, 2.0, 2.3, 2.4, 1.7, 2.0, 1.9, 2.1, 2.3, 1.8, 2.0, 2.2, 1.9, 2.1, 2.4, 1.7, 2.2, 2.0, 1.8, 2.3, 2.1]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print(f'F-statistic: {f_statistic}')\n",
    "print(f'p-value: {p_value}')\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set your desired level of significance\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f0713",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Software': ['A', 'B', 'C'] * 10,  # Repeat each software type 10 times\n",
    "    'Experience': ['Novice', 'Experienced'] * 15,  # Alternate between novice and experienced\n",
    "    'Time': [18, 22, 20, 24, 26, 25, 21, 19, 23, 27, 29, 28, 22, 21, 24, 23, 27, 25, 20, 19, 30, 28, 26, 29, 24, 23, 25, 22, 21, 27]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "formula = 'Time ~ Software + Experience + Software:Experience'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0f6e1",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2c0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -8.820332080639565\n",
      "p-value: 2.6275608233977534e-12\n",
      "There is a significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Sample data for the control and experimental groups\n",
    "control_group = [85, 78, 90, 92, 87, 82, 88, 89, 75, 80, 79, 81, 86, 84, 83, 87, 88, 76, 91, 79, 82, 89, 90, 85, 84, 81, 77, 80, 86, 88]\n",
    "experimental_group = [92, 88, 97, 96, 93, 91, 95, 94, 88, 91, 90, 89, 92, 93, 97, 96, 95, 90, 89, 91, 94, 93, 96, 92, 90, 94, 93, 97, 95, 96]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Report the results\n",
    "print(f't-statistic: {t_statistic}')\n",
    "print(f'p-value: {p_value}')\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Set your desired level of significance\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a732d0",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc728cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq    df           F        PR(>F)\n",
      "Intercept  7277.112500   1.0  576.391831  8.118776e-32\n",
      "C(Store)     82.400000   2.0    3.263292  4.539314e-02\n",
      "C(Day)      659.433333  29.0    1.801074  2.854904e-02\n",
      "Residual    732.266667  58.0         NaN           NaN\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  3.2633 2.0000 58.0000 0.0454\n",
      "===================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Store': ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30,\n",
    "    'Day': list(range(1, 31)) * 3,\n",
    "    'Sales': [50, 55, 48, 60, 58, 53, 45, 49, 47, 51, 57, 52, 55, 49, 53, 50, 56, 58, 52, 46, 53, 57, 55, 48, 50, 54, 49, 46, 51, 56] +\n",
    "             [45, 47, 42, 53, 49, 46, 44, 43, 48, 51, 52, 47, 49, 50, 55, 57, 58, 53, 49, 46, 54, 56, 52, 48, 45, 49, 47, 51, 56, 55] +\n",
    "             [55, 57, 52, 50, 56, 49, 47, 51, 53, 58, 55, 52, 56, 48, 45, 54, 50, 49, 46, 53, 46, 49, 55, 52, 51, 57, 48, 50, 53, 54]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "formula = 'Sales ~ C(Store) + C(Day)'\n",
    "model = ols(formula, data=df).fit()\n",
    "aov_table = sm.stats.anova_lm(model, typ=3)\n",
    "\n",
    "# Report the results\n",
    "print(aov_table)\n",
    "\n",
    "# Perform post-hoc tests (e.g., Tukey's HSD)\n",
    "posthoc = AnovaRM(df, 'Sales', 'Day', within=['Store'])\n",
    "posthoc_results = posthoc.fit()\n",
    "\n",
    "# Report post-hoc results\n",
    "print(posthoc_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344aba70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
